{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flipkart Product category Classification using  Product description",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNKYvWTs//5f/Tpmr9tzW+N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theyashmishra/Flipkart-Product-category-Classification-using-product-description/blob/main/Flipkart_Product_category_Classification_using_Product_description.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWwt7NwJIHyp"
      },
      "source": [
        "**NLP**: Product category prediction using product description\n",
        "                                      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcImOQrAIo9e"
      },
      "source": [
        "1. In this block all important libraries are imported which are going to use in the model building(sklearn.naive_bayes,sklearn.linear_model),visualization(seaborn,matplotlib),text cleaning(nltk,restem.porter,stopwords),data preprocessing(labelencoder,standardscaler)\n",
        "\n",
        "2. These libraries makes things easy and flexible.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIwqq3kbesKM",
        "outputId": "162e6454-47b7-4f31-b9e8-e4ac34cd5dda"
      },
      "source": [
        "#library for dataframe and its operations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#library for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#text cleaning libraries\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#data preprocessing libraries  \n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "#library for importing models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "#libraries to determine model validity\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "nHL9hc5_fnwK",
        "outputId": "8cf15ba0-dc18-4db9-d60c-6f55a74481b1"
      },
      "source": [
        "#data reading just upload data to session storage and use it\n",
        "df1=pd.read_excel(\"flipkart_com-ecommerce_sample - flipkart_com-ecommerce_sample.xlsx\")\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniq_id</th>\n",
              "      <th>crawl_timestamp</th>\n",
              "      <th>product_url</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_category_tree</th>\n",
              "      <th>pid</th>\n",
              "      <th>retail_price</th>\n",
              "      <th>discounted_price</th>\n",
              "      <th>image</th>\n",
              "      <th>is_FK_Advantage_product</th>\n",
              "      <th>description</th>\n",
              "      <th>product_rating</th>\n",
              "      <th>overall_rating</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_specifications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c2d766ca982eca8304150849735ffef9</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/alisha-solid-women-s-c...</td>\n",
              "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
              "      <td>[\"Clothing &gt;&gt; Women's Clothing &gt;&gt; Lingerie, Sl...</td>\n",
              "      <td>SRTEH2FF9KEDEFGF</td>\n",
              "      <td>999.0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/short/u/4/a/...</td>\n",
              "      <td>False</td>\n",
              "      <td>Key Features of Alisha Solid Women's Cycling S...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Alisha</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Number of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7f7036a6d550aaa89d34c77bd39a5e48</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/fabhomedecor-fabric-do...</td>\n",
              "      <td>FabHomeDecor Fabric Double Sofa Bed</td>\n",
              "      <td>[\"Furniture &gt;&gt; Living Room Furniture &gt;&gt; Sofa B...</td>\n",
              "      <td>SBEEH3QGU7MFYJFY</td>\n",
              "      <td>32157.0</td>\n",
              "      <td>22646.0</td>\n",
              "      <td>[\"http://img6a.flixcart.com/image/sofa-bed/j/f...</td>\n",
              "      <td>False</td>\n",
              "      <td>FabHomeDecor Fabric Double Sofa Bed (Finish Co...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>FabHomeDecor</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Installati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f449ec65dcbc041b6ae5e6a32717d01b</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/aw-bellies/p/itmeh4grg...</td>\n",
              "      <td>AW Bellies</td>\n",
              "      <td>[\"Footwear &gt;&gt; Women's Footwear &gt;&gt; Ballerinas &gt;...</td>\n",
              "      <td>SHOEH4GRSUBJGZXE</td>\n",
              "      <td>999.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/shoe/7/z/z/r...</td>\n",
              "      <td>False</td>\n",
              "      <td>Key Features of AW Bellies Sandals Wedges Heel...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>AW</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Ideal For\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0973b37acd0c664e3de26e97e5571454</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/alisha-solid-women-s-c...</td>\n",
              "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
              "      <td>[\"Clothing &gt;&gt; Women's Clothing &gt;&gt; Lingerie, Sl...</td>\n",
              "      <td>SRTEH2F6HUZMQ6SJ</td>\n",
              "      <td>699.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/short/6/2/h/...</td>\n",
              "      <td>False</td>\n",
              "      <td>Key Features of Alisha Solid Women's Cycling S...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Alisha</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Number of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bc940ea42ee6bef5ac7cea3fb5cfbee7</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/sicons-all-purpose-arn...</td>\n",
              "      <td>Sicons All Purpose Arnica Dog Shampoo</td>\n",
              "      <td>[\"Pet Supplies &gt;&gt; Grooming &gt;&gt; Skin &amp; Coat Care...</td>\n",
              "      <td>PSOEH3ZYDMSYARJ5</td>\n",
              "      <td>220.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/pet-shampoo/...</td>\n",
              "      <td>False</td>\n",
              "      <td>Specifications of Sicons All Purpose Arnica Do...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Sicons</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Pet Type\",...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            uniq_id  ...                             product_specifications\n",
              "0  c2d766ca982eca8304150849735ffef9  ...  {\"product_specification\"=>[{\"key\"=>\"Number of ...\n",
              "1  7f7036a6d550aaa89d34c77bd39a5e48  ...  {\"product_specification\"=>[{\"key\"=>\"Installati...\n",
              "2  f449ec65dcbc041b6ae5e6a32717d01b  ...  {\"product_specification\"=>[{\"key\"=>\"Ideal For\"...\n",
              "3  0973b37acd0c664e3de26e97e5571454  ...  {\"product_specification\"=>[{\"key\"=>\"Number of ...\n",
              "4  bc940ea42ee6bef5ac7cea3fb5cfbee7  ...  {\"product_specification\"=>[{\"key\"=>\"Pet Type\",...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYmnKis-MCrY"
      },
      "source": [
        "In this block I have dropped the columns which are of no use or do not contribute in model accuracy.the intution behind doing  is that it will decrease runtime and avoid redundancy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITzWfltkg9bn",
        "outputId": "224cbb32-bd17-4097-b83f-311e3e0cb3c3"
      },
      "source": [
        "print(df1.columns)\n",
        "df1.drop(['uniq_id', 'crawl_timestamp', 'product_url','pid', 'retail_price', 'discounted_price','image', 'is_FK_Advantage_product','product_rating',\n",
        "       'overall_rating', ], axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['uniq_id', 'crawl_timestamp', 'product_url', 'product_name',\n",
            "       'product_category_tree', 'pid', 'retail_price', 'discounted_price',\n",
            "       'image', 'is_FK_Advantage_product', 'description', 'product_rating',\n",
            "       'overall_rating', 'brand', 'product_specifications'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDKXQnycMeVI"
      },
      "source": [
        "To check for Null values in descriptions as they produced error before while making bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "C8C5v32rhEO5",
        "outputId": "821c039c-6247-4c51-c376-8d54bb865671"
      },
      "source": [
        "df1[df1['description'].isnull()==True]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_category_tree</th>\n",
              "      <th>description</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_specifications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>Ozel Studio Casual Sleeveless Printed Women's Top</td>\n",
              "      <td>[\"Clothing &gt;&gt; Women's Clothing &gt;&gt; Western Wear...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Ideal For\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17299</th>\n",
              "      <td>Amore Abstract Cushions Cover</td>\n",
              "      <td>[\"Home Furnishing &gt;&gt; Cushions, Pillows &amp; Cover...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Amore</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            product_name  ...                             product_specifications\n",
              "553    Ozel Studio Casual Sleeveless Printed Women's Top  ...  {\"product_specification\"=>[{\"key\"=>\"Ideal For\"...\n",
              "17299                      Amore Abstract Cushions Cover  ...  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq5AJLRjN1Dz"
      },
      "source": [
        "In this block I am deleting these null records as there are 20000 records and these 2 are negligible to it and also these are not unique so we are not losing any information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhJc7Wg-hR-s"
      },
      "source": [
        "df1.drop(labels=[553,17299],axis=0,inplace =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m08Pk4FzOnUD"
      },
      "source": [
        "**Text preprocessing**:In this block we are preprocessing text\n",
        "1. First we imported porterstemmer module which is used for stemming text data.\n",
        "2. I have done preprocessing mainly on 2 columns 'product_category_tree' and 'description'.\n",
        "3. I have ignored the deleted rows(553 and 17299)\n",
        "4. first in 'product_category_tree' I removed all the elements except alphabets and spaces then i convert it all in lowercase elements and then split it and join using space and appended in the list corpus.\n",
        "5. Secondly in 'description' column I removed all the elements except alphabets and spaces then i convert it all in lowercase elements after that I have deleted all the stopwords present in the description and done the stemming using porterstemmer module then split it and join it using space and appended in the list crpus\n",
        "6. This is the basic operation for any NLP project\n",
        "7. I have used set during stemming to improve runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P7lrisOia2j"
      },
      "source": [
        "crpus=[]\n",
        "ps=PorterStemmer()\n",
        "corpus=[]\n",
        "for i in range(0,20000):\n",
        " if i!=553 and i!=17299:\n",
        "  review=re.sub('[^a-zA-Z]',' ',df1['product_category_tree'][i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "#we use set here with stopwords to reduce execution time\n",
        "  review=' '.join(review)\n",
        "  corpus.append(review)\n",
        "#description preprocessing\n",
        "  review=re.sub('[^a-zA-Z]',' ',df1['description'][i])\n",
        "  \n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[ps.stem(word )for word in review if not word in set(stopwords.words('english'))]\n",
        "  review=' '.join(review)\n",
        "  crpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgYye6Y9RIbz"
      },
      "source": [
        "In this block I have created a separate dataframe of preprocessed text to improve readability of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ipsF6QP5ifmL",
        "outputId": "669f68a0-cacb-49b2-e8e0-b5b175657793"
      },
      "source": [
        "#declaring and showing dataframe\n",
        "df=pd.DataFrame({\"product_category\":corpus,\"description\":crpus})\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_category</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clothing women s clothing lingerie sleep swimw...</td>\n",
              "      <td>key featur alisha solid women cycl short cotto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>furniture living room furniture sofa beds futo...</td>\n",
              "      <td>fabhomedecor fabric doubl sofa bed finish colo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>footwear women s footwear ballerinas aw bellies</td>\n",
              "      <td>key featur aw belli sandal wedg heel casual aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clothing women s clothing lingerie sleep swimw...</td>\n",
              "      <td>key featur alisha solid women cycl short cotto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pet supplies grooming skin coat care shampoo s...</td>\n",
              "      <td>specif sicon purpos arnica dog shampoo ml gene...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    product_category                                        description\n",
              "0  clothing women s clothing lingerie sleep swimw...  key featur alisha solid women cycl short cotto...\n",
              "1  furniture living room furniture sofa beds futo...  fabhomedecor fabric doubl sofa bed finish colo...\n",
              "2    footwear women s footwear ballerinas aw bellies  key featur aw belli sandal wedg heel casual aw...\n",
              "3  clothing women s clothing lingerie sleep swimw...  key featur alisha solid women cycl short cotto...\n",
              "4  pet supplies grooming skin coat care shampoo s...  specif sicon purpos arnica dog shampoo ml gene..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyYtorlmROlW"
      },
      "source": [
        "I have figure out that main category of the data lies in the begining of product_category column elements so I have cut a strip of first word and treat it as a class itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXGgu7A-ijWc"
      },
      "source": [
        "df['product_category'] = df['product_category'].apply(lambda x : x.split()[0][0:].strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPtahZo-RrNh"
      },
      "source": [
        "**Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "wRfHgxWXDYVd",
        "outputId": "13335963-2a7c-4fdf-95e9-c8dbaf2476c3"
      },
      "source": [
        "#this is distplot of df.groupby(['description']).size(), i used it as it is a combination of rugplot and kdeplot\n",
        "plt.figure(figsize=(30,70))\n",
        "sns.displot( df.groupby(['description']).size(),kde=False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x5040 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "wmgtTqmbGshG",
        "outputId": "e7cf7d4c-f16f-42e3-9a5f-0f456ca2fe70"
      },
      "source": [
        "#this is distplot of df.groupby([''product_category'']).size(), i used it as it is a combination of rugplot and kdeplot\n",
        "plt.figure(figsize=(30,70))\n",
        "sns.displot( df.groupby(['product_category']).size(),kde=False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x5040 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VjsItZ7SqWr"
      },
      "source": [
        "**Data Labelling**\n",
        "\n",
        "*  In this block I used count vectorizer on 'description' column  because ountVectorizer is used to convert a collection of text documents to a vector of term/token counts.\n",
        "*   I used LabelEncoder on 'product_category' column because it can normalize variables and labelencoder also convert non numerical to numerical variables.\n",
        "*  I used train_test_split to split the data into training set and test set I used 75% data for training purpose to avoid overfitting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKaYFBcTiyYa"
      },
      "source": [
        "X=df['description']\n",
        "y=df['product_category']\n",
        "cv= CountVectorizer()\n",
        "X=cv.fit_transform(X)\n",
        "le=LabelEncoder()\n",
        "le=le.fit(y)\n",
        "y=le.transform(y)\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG2mhUknUHqL"
      },
      "source": [
        "**Model Building**: In this part I have made 2 models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rou_q_b3UrZ8"
      },
      "source": [
        "**Multinomial Naive bayes Classifier**:It is a really good model when we have to classify text data into multiple categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYH2KyO4jDXo"
      },
      "source": [
        "#Multinomial Naive bayes\n",
        "mnb=MultinomialNB()\n",
        "#model fitting\n",
        "mnb.fit(X_train,y_train)\n",
        "#prediction\n",
        "pre=mnb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_krofJaHU-FO"
      },
      "source": [
        "* This block and the block below this is used for model validation, in this block we calculated accuracy and classification report of the model and check underfitting.\n",
        "* In the block below this block we checked overfitting  by observing difference in model accuracies when prediction is done in test set and training set(if difference is high then there is overfitting and if diffrence is low there is no overfitting).\n",
        "* These methods tells us how good our model is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUEyXpYajfp7",
        "outputId": "cca060b3-4571-4215-f06c-8758eb057a50"
      },
      "source": [
        "#check accuracy and underfitting using classification report and accuracy score\n",
        "r=accuracy_score(y_test,pre)\n",
        "print(r)\n",
        "print(classification_report(y_test,pre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9144\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          16       0.92      0.99      0.95       239\n",
            "          18       0.81      0.61      0.70       116\n",
            "          19       0.84      0.62      0.72        87\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.86      0.96      0.91       184\n",
            "          26       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       1.00      0.18      0.31        22\n",
            "          35       0.00      0.00      0.00         1\n",
            "          37       0.96      0.99      0.97      1538\n",
            "          38       0.00      0.00      0.00         6\n",
            "          40       0.87      0.81      0.84       146\n",
            "          41       0.00      0.00      0.00         1\n",
            "          44       0.00      0.00      0.00         2\n",
            "          47       0.00      0.00      0.00         1\n",
            "          48       0.00      0.00      0.00         1\n",
            "          49       0.00      0.00      0.00         3\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       1.00      0.50      0.67         2\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       0.00      0.00      0.00         1\n",
            "          58       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          64       0.93      0.97      0.95       279\n",
            "          65       0.00      0.00      0.00         2\n",
            "          67       0.93      0.98      0.95        52\n",
            "          69       1.00      0.75      0.86         8\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       1.00      0.67      0.80         6\n",
            "          76       0.87      0.94      0.90       444\n",
            "          77       1.00      1.00      1.00         1\n",
            "          78       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         1\n",
            "          81       0.00      0.00      0.00         1\n",
            "          84       0.88      1.00      0.93       872\n",
            "          93       0.97      0.83      0.90       161\n",
            "          94       0.00      0.00      0.00         1\n",
            "          99       1.00      1.00      1.00         1\n",
            "         101       0.00      0.00      0.00         1\n",
            "         102       0.00      0.00      0.00         1\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.00      0.00      0.00         1\n",
            "         105       0.00      0.00      0.00         1\n",
            "         108       0.00      0.00      0.00         1\n",
            "         110       0.00      0.00      0.00         2\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.97      0.92      0.95       280\n",
            "         114       0.00      0.00      0.00         2\n",
            "         118       0.00      0.00      0.00         1\n",
            "         123       0.00      0.00      0.00         4\n",
            "         126       0.91      0.54      0.68        72\n",
            "         127       1.00      0.62      0.77         8\n",
            "         128       0.00      0.00      0.00         1\n",
            "         142       0.00      0.00      0.00         1\n",
            "         143       0.00      0.00      0.00         1\n",
            "         145       0.00      0.00      0.00         1\n",
            "         147       0.00      0.00      0.00         1\n",
            "         151       0.00      0.00      0.00         1\n",
            "         152       0.00      0.00      0.00         1\n",
            "         153       0.00      0.00      0.00         1\n",
            "         154       0.00      0.00      0.00         1\n",
            "         156       0.00      0.00      0.00         2\n",
            "         160       0.00      0.00      0.00         1\n",
            "         161       0.91      0.50      0.65        40\n",
            "         166       0.00      0.00      0.00         1\n",
            "         168       0.78      1.00      0.88        14\n",
            "         170       0.00      0.00      0.00         1\n",
            "         172       0.00      0.00      0.00         1\n",
            "         173       0.00      0.00      0.00         1\n",
            "         175       0.00      0.00      0.00         1\n",
            "         176       0.00      0.00      0.00         1\n",
            "         177       0.92      0.91      0.91       119\n",
            "         178       0.73      0.74      0.74        89\n",
            "         179       0.00      0.00      0.00         1\n",
            "         181       0.00      0.00      0.00         1\n",
            "         183       0.00      0.00      0.00         1\n",
            "         185       0.00      0.00      0.00         1\n",
            "         187       0.00      0.00      0.00         3\n",
            "         188       0.00      0.00      0.00         1\n",
            "         189       0.00      0.00      0.00         1\n",
            "         190       0.95      1.00      0.98       127\n",
            "         191       0.00      0.00      0.00         1\n",
            "         192       0.00      0.00      0.00         1\n",
            "         193       0.00      0.00      0.00         1\n",
            "         194       0.00      0.00      0.00         1\n",
            "         195       0.00      0.00      0.00         1\n",
            "         197       0.00      0.00      0.00         1\n",
            "         198       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.91      5000\n",
            "   macro avg       0.25      0.22      0.23      5000\n",
            "weighted avg       0.90      0.91      0.90      5000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1pr80bBv2bL",
        "outputId": "53420e99-9f8e-40a8-ba69-5271014588fb"
      },
      "source": [
        "#check overfitting for multinomial Naive bayes using diffrence in accuracy when model predicts on X_test and X_train\n",
        "print(\"accuracy on test set: \", accuracy_score(y_test,pre))\n",
        "print(\"accuracy on training set: \", accuracy_score(y_train,mnb.predict(X_train)))\n",
        "#here diffrence in accuracy is very less which shows out model is NOT overfitting"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on test set:  0.9144\n",
            "accuracy on training set:  0.934191225496733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqbdwRF9yPFs"
      },
      "source": [
        "**Logistic Regression**:I have made this Model in hope fto get much better results than multiple Naivebayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJykoYaVjm4y",
        "outputId": "9bc3118e-1a15-44ee-bd60-a8df4005346b"
      },
      "source": [
        "lr=LogisticRegression()\n",
        "#Model fitting\n",
        "lr.fit(X_train,y_train)\n",
        "#model prediction\n",
        "pre=lr.predict(X_test)\n",
        "#Model performance calcutation and check whether underfitting is there or not.\n",
        "r=accuracy_score(y_test,pre)\n",
        "cm=confusion_matrix(y_test,pre)\n",
        "print(r)\n",
        "\n",
        "print(classification_report(y_test,pre))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9568\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       1.00      0.50      0.67         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          16       0.98      0.98      0.98       239\n",
            "          18       0.91      0.84      0.88       116\n",
            "          19       0.94      0.98      0.96        87\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.95      0.95      0.95       184\n",
            "          26       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.91      0.95      0.93        22\n",
            "          35       0.00      0.00      0.00         1\n",
            "          37       0.97      0.99      0.98      1538\n",
            "          38       0.40      0.33      0.36         6\n",
            "          40       0.94      0.97      0.95       146\n",
            "          41       0.00      0.00      0.00         1\n",
            "          44       1.00      1.00      1.00         2\n",
            "          47       0.00      0.00      0.00         1\n",
            "          48       0.00      0.00      0.00         1\n",
            "          49       1.00      1.00      1.00         3\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       1.00      0.50      0.67         2\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       0.00      0.00      0.00         1\n",
            "          58       1.00      1.00      1.00         2\n",
            "          60       0.50      1.00      0.67         1\n",
            "          61       0.00      0.00      0.00         0\n",
            "          64       0.97      0.99      0.98       279\n",
            "          65       0.00      0.00      0.00         2\n",
            "          67       0.98      0.96      0.97        52\n",
            "          69       1.00      0.88      0.93         8\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       0.86      1.00      0.92         6\n",
            "          76       0.94      0.95      0.94       444\n",
            "          77       0.00      0.00      0.00         1\n",
            "          78       0.00      0.00      0.00         1\n",
            "          80       1.00      1.00      1.00         1\n",
            "          81       0.00      0.00      0.00         1\n",
            "          84       1.00      0.99      0.99       872\n",
            "          88       0.00      0.00      0.00         0\n",
            "          93       0.92      0.95      0.93       161\n",
            "          94       0.00      0.00      0.00         1\n",
            "          97       0.00      0.00      0.00         0\n",
            "          99       1.00      1.00      1.00         1\n",
            "         101       0.00      0.00      0.00         1\n",
            "         102       1.00      1.00      1.00         1\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.00      0.00      0.00         1\n",
            "         105       1.00      1.00      1.00         1\n",
            "         108       0.00      0.00      0.00         1\n",
            "         110       0.00      0.00      0.00         2\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.96      0.97      0.96       280\n",
            "         114       0.00      0.00      0.00         2\n",
            "         118       0.00      0.00      0.00         1\n",
            "         123       0.60      0.75      0.67         4\n",
            "         124       0.00      0.00      0.00         0\n",
            "         126       0.79      0.75      0.77        72\n",
            "         127       1.00      0.88      0.93         8\n",
            "         128       0.00      0.00      0.00         1\n",
            "         142       0.50      1.00      0.67         1\n",
            "         143       0.00      0.00      0.00         1\n",
            "         145       0.00      0.00      0.00         1\n",
            "         147       0.00      0.00      0.00         1\n",
            "         148       0.00      0.00      0.00         0\n",
            "         151       0.00      0.00      0.00         1\n",
            "         152       0.25      1.00      0.40         1\n",
            "         153       0.50      1.00      0.67         1\n",
            "         154       0.00      0.00      0.00         1\n",
            "         156       0.00      0.00      0.00         2\n",
            "         160       1.00      1.00      1.00         1\n",
            "         161       0.95      0.88      0.91        40\n",
            "         166       0.00      0.00      0.00         1\n",
            "         168       0.91      0.71      0.80        14\n",
            "         170       0.00      0.00      0.00         1\n",
            "         172       0.00      0.00      0.00         1\n",
            "         173       1.00      1.00      1.00         1\n",
            "         175       0.00      0.00      0.00         1\n",
            "         176       1.00      1.00      1.00         1\n",
            "         177       0.98      0.94      0.96       119\n",
            "         178       0.82      0.84      0.83        89\n",
            "         179       1.00      1.00      1.00         1\n",
            "         181       0.00      0.00      0.00         1\n",
            "         183       1.00      1.00      1.00         1\n",
            "         185       0.00      0.00      0.00         1\n",
            "         187       1.00      1.00      1.00         3\n",
            "         188       0.00      0.00      0.00         1\n",
            "         189       0.00      0.00      0.00         1\n",
            "         190       0.99      1.00      1.00       127\n",
            "         191       0.00      0.00      0.00         1\n",
            "         192       0.00      0.00      0.00         1\n",
            "         193       0.00      0.00      0.00         1\n",
            "         194       0.00      0.00      0.00         1\n",
            "         195       0.00      0.00      0.00         1\n",
            "         196       0.00      0.00      0.00         0\n",
            "         197       0.00      0.00      0.00         1\n",
            "         198       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.96      5000\n",
            "   macro avg       0.40      0.41      0.39      5000\n",
            "weighted avg       0.95      0.96      0.95      5000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj8hnVXFWrqb"
      },
      "source": [
        "**checking Accuracy**\n",
        "* The Block below is used to calculate accuracy and to check underfitting\n",
        "* the Block below this block is used to check overfitting  by observing difference in model accuracies when prediction is done in test set and training set(if difference is high then there is overfitting and if diffrence is low there is no overfitting)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vohpi8B6kR7T",
        "outputId": "3f53b916-b4c0-4444-cf9f-05231417aee5"
      },
      "source": [
        "#Model gives accuracy of 96 percent which is better than  multinomail naive bayes\n",
        "#check overfitting for multinoial Logistic regression using diffrence in accuracy when model predicts on X_test and X_train\n",
        "print(\"accuracy on test set: \", accuracy_score(y_test,pre))\n",
        "print(\"accuracy on training set: \", accuracy_score(y_train,lr.predict(X_train)))\n",
        "#here difference in accuracy is very less hence model is NOT overfitting \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on test set:  0.9568\n",
            "accuracy on training set:  0.9970662755034004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky57TDeEXbFA"
      },
      "source": [
        "**Hence we see that there is also no overfitting in logistic regression model but this model do not converge to local optima so I prefered Multinomial Naive bayes algorithm I have used other algorithms(Randomforest,xgboost,etc) also but the RAM crashed during fitting phase so i end up with these two models and also these two model give fair results.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPoOZD9Bsrk1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}